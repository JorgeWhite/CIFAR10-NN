{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network to classify the CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as cm\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_corrects(net, batch, labels, func=None):\n",
    "    '''Given a batch and its lables, it counts the number of corrects answers of a NN, func parameter applies \n",
    "    a modification to the tensor that contains the data.'''\n",
    "    \n",
    "    if func is not None:\n",
    "        batch = func(batch)\n",
    "        output = net(batch)\n",
    "    else:\n",
    "        output = net(batch)\n",
    "    answers = output.max(dim=1)[1]\n",
    "    correct_quantity = (answers==labels).sum()\n",
    "    return correct_quantity\n",
    "\n",
    "def calculate_global_precision(net, data_loader, batch_size, func=None, cuda=False):\n",
    "    '''Calculate the precision of a NN given a data_loader, it receives a function that transforms the data'''\n",
    "    correct = 0\n",
    "    for (images, labels) in data_loader:\n",
    "        if (cuda and torch.cuda.is_available()):\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        correct += count_corrects(net, images, labels, func)\n",
    "    correct = correct.data.tolist()\n",
    "    return (100*correct)/(len(data_loader)*batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5135f6d7306487b80c6e76c6ba5a689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Load the data and divide it in train/test\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the classification problem we're going to use a neural network with the next arquitecture:\n",
    "\n",
    " An convolutional layer with a (5, 5) filter and 64 output filters with ReLu activation function.\n",
    " A maxpooling layer of (3, 3)\n",
    " Another convolutional layer with a (5, 5) filter and 32 filter output filters with ReLu activation function.\n",
    " A maxpooling layer of (3, 3)\n",
    " A fully connected layer with 384 neurons, ReLu activation function.\n",
    " A fully connected layer with 192 neurons, ReLu activation function.\n",
    " An output layer with 10 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CIFAR_NET(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''Initialize the network'''\n",
    "        super(CIFAR_NET, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "             # First convolutional layer, the input datatype are images with RGB so it will have 3 inputs and 64 outputs.\n",
    "             nn.Conv2d(3, 64, 5),\n",
    "             nn.ReLU(),\n",
    "             # Pooling with stride 2\n",
    "             nn.AvgPool2d(2, stride=2)\n",
    "        )\n",
    "            \n",
    "        self.features1 = nn.Sequential(\n",
    "            # Second layer with 64 inputs and 32 outputs.\n",
    "            nn.Conv2d(64, 32, 5),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            ## Pooling with stride = 3\n",
    "            nn.AvgPool2d(3, stride=3)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            # Finally we use 2 fully connected layers\n",
    "            nn.Linear(288, 384),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(384, 192),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(192, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Defines the order of the forward propagation.\n",
    "        '''\n",
    "        x = self.features(x)\n",
    "        x = self.features1(x)\n",
    "        # It is necessary to flatten the data.\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def train_cnn(self, model, data_loader, criterion, optimizer, cuda=Fasle):\n",
    "        '''\n",
    "        Defines the training function\n",
    "        '''\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_acc = 0.0\n",
    "        ind = 0\n",
    "        for epoch in range(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
